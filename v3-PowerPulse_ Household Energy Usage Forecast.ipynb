{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06db4e3b-66f8-4b2d-9249-9198df6e3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1a1e52-7189-445c-93fd-8b9aa7257e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Config -----------------\n",
    "DATA_PATH = \"household_power_consumption.txt\"  # Change if needed\n",
    "SEP = \";\"\n",
    "NA_VALUES = [\"?\"]\n",
    "RANDOM_STATE = 42\n",
    "ROLLING_WINDOW = 7   # hours\n",
    "SAMPLE_FRAC = 1.0    # set <1 for faster testing\n",
    "TARGET = \"Global_active_power\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6572a1ac-29d9-42b2-b410-5df3bf88dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Shape: (2075259, 9)\n",
      "Columns: ['Date', 'Time', 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n"
     ]
    }
   ],
   "source": [
    "# 2) Load Data\n",
    "# =====================================================\n",
    "print(\"Loading dataset...\")\n",
    "data = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    sep=SEP,\n",
    "    na_values=NA_VALUES,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "if SAMPLE_FRAC < 1.0:\n",
    "    data = data.sample(frac=SAMPLE_FRAC, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "    print(f\"Sampled {SAMPLE_FRAC*100:.0f}% of data.\")\n",
    "\n",
    "print(\"Shape:\", data.shape)\n",
    "print(\"Columns:\", list(data.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dda224-ee3f-4f88-9ee7-6d897618893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing DateTime...\n",
      "Dropped 0 invalid DateTime rows.\n",
      "Missing counts before imputation:\n",
      " Global_active_power      25979\n",
      "Global_reactive_power    25979\n",
      "Voltage                  25979\n",
      "Global_intensity         25979\n",
      "Sub_metering_1           25979\n",
      "Sub_metering_2           25979\n",
      "Sub_metering_3           25979\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) Parse DateTime & Clean\n",
    "# =====================================================\n",
    "print(\"Parsing DateTime...\")\n",
    "data[\"DateTime\"] = pd.to_datetime(\n",
    "    data[\"Date\"].astype(str) + \" \" + data[\"Time\"].astype(str),\n",
    "    format=\"%d/%m/%Y %H:%M:%S\",\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "before = len(data)\n",
    "data = data.dropna(subset=[\"DateTime\"]).copy()\n",
    "print(f\"Dropped {before - len(data)} invalid DateTime rows.\")\n",
    "\n",
    "# Sort for rolling features\n",
    "data = data.sort_values(\"DateTime\").reset_index(drop=True)\n",
    "\n",
    "# Convert measurement columns to numeric\n",
    "num_cols_raw = [\n",
    "    \"Global_active_power\", \"Global_reactive_power\", \"Voltage\",\n",
    "    \"Global_intensity\", \"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\"\n",
    "]\n",
    "for col in num_cols_raw:\n",
    "    data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "\n",
    "# Replace negatives with NaN\n",
    "for col in num_cols_raw:\n",
    "    neg_ct = (data[col] < 0).sum(skipna=True)\n",
    "    if neg_ct > 0:\n",
    "        print(f\"{col}: found {neg_ct} negatives → set to NaN.\")\n",
    "        data.loc[data[col] < 0, col] = np.nan\n",
    "\n",
    "print(\"Missing counts before imputation:\\n\", data[num_cols_raw].isna().sum())\n",
    "\n",
    "# Drop original Date/Time strings\n",
    "data.drop(columns=[\"Date\", \"Time\"], inplace=True, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86419911-1660-49c8-b0f9-15fd41b2f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features...\n"
     ]
    }
   ],
   "source": [
    "# 4) Feature Engineering\n",
    "# =====================================================\n",
    "print(\"Engineering features...\")\n",
    "\n",
    "# Date-related\n",
    "data[\"Date_only\"] = data[\"DateTime\"].dt.date\n",
    "data[\"Hour\"] = data[\"DateTime\"].dt.hour\n",
    "data[\"Month\"] = data[\"DateTime\"].dt.month\n",
    "data[\"Weekday\"] = data[\"DateTime\"].dt.weekday\n",
    "data[\"Is_Weekend\"] = data[\"Weekday\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# Daily average\n",
    "daily_avg = (\n",
    "    data.groupby(\"Date_only\")[\"Global_active_power\"]\n",
    "        .mean()\n",
    "        .reset_index(name=\"Daily_Avg_Power\")\n",
    ")\n",
    "data = data.merge(daily_avg, on=\"Date_only\", how=\"left\")\n",
    "\n",
    "# Peak hour fix — skip all-NaN days\n",
    "valid_days = data.groupby(\"Date_only\")[\"Global_active_power\"].transform(lambda x: x.notna().any())\n",
    "data_valid_peak = data[valid_days]\n",
    "idxmax_per_day = data_valid_peak.groupby(\"Date_only\")[\"Global_active_power\"].idxmax()\n",
    "idxmax_per_day = idxmax_per_day.dropna().astype(int)\n",
    "peak_hours = (\n",
    "    data.loc[idxmax_per_day, [\"Date_only\", \"Hour\"]]\n",
    "        .rename(columns={\"Hour\": \"Peak_Hour\"})\n",
    ")\n",
    "data = data.merge(peak_hours, on=\"Date_only\", how=\"left\")\n",
    "\n",
    "# Rolling average\n",
    "data[\"Rolling_Avg_Power\"] = (\n",
    "    data[\"Global_active_power\"]\n",
    "    .rolling(window=ROLLING_WINDOW, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Fill missing target before splitting\n",
    "target_median = data[TARGET].median()\n",
    "data[TARGET] = data[TARGET].fillna(target_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4823313f-15fa-4f67-9b79-17e73a338b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting train/test...\n",
      "Train size: (1660207, 13), Test size: (415052, 13)\n"
     ]
    }
   ],
   "source": [
    "# 5) Train/Test Split (Chronological)\n",
    "# =====================================================\n",
    "print(\"Splitting train/test...\")\n",
    "exclude_cols = {\"DateTime\", \"Date_only\", TARGET}\n",
    "feature_cols = [c for c in data.columns if c not in exclude_cols]\n",
    "\n",
    "n = len(data)\n",
    "split_idx = int(n * 0.8)\n",
    "train = data.iloc[:split_idx].copy()\n",
    "test = data.iloc[split_idx:].copy()\n",
    "\n",
    "X_train, y_train = train[feature_cols], train[TARGET]\n",
    "X_test, y_test = test[feature_cols], test[TARGET]\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b46e1e-6c4f-41d2-bc5d-59e44343be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Preprocessors\n",
    "# =====================================================\n",
    "numeric_features = X_train.columns.tolist()\n",
    "\n",
    "preprocess_scaled = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "preprocess_tree = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76f154c-8f60-4a96-b27c-cc6c5b7f2863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Models\n",
    "# =====================================================\n",
    "models = {\n",
    "    \"Linear Regression\": Pipeline([\n",
    "        (\"prep\", preprocess_scaled),\n",
    "        (\"model\", LinearRegression())\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        (\"prep\", preprocess_tree),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ))\n",
    "    ]),\n",
    "    \"Gradient Boosting\": Pipeline([\n",
    "        (\"prep\", preprocess_tree),\n",
    "        (\"model\", GradientBoostingRegressor(\n",
    "            n_estimators=200, random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ]),\n",
    "    \"Neural Network\": Pipeline([\n",
    "        (\"prep\", preprocess_scaled),\n",
    "        (\"model\", MLPRegressor(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            learning_rate_init=1e-3,\n",
    "            max_iter=50,\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6792a84-b432-4826-aba3-523dc081f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "→ Linear Regression\n",
      "\n",
      "[Linear Regression] RMSE: 0.0387 | MAE: 0.0235 | R²: 0.9981\n",
      "→ Random Forest\n"
     ]
    }
   ],
   "source": [
    "# 8) Train & Evaluate\n",
    "# =====================================================\n",
    "def eval_regression(y_true, y_pred, label=\"\"):\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)  # updated to avoid warning\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n[{label}] RMSE: {rmse:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")\n",
    "    return {\"model\": label, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "results = []\n",
    "fitted_models = {}\n",
    "\n",
    "print(\"Training models...\")\n",
    "for name, pipe in models.items():\n",
    "    print(f\"→ {name}\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    results.append(eval_regression(y_test, preds, label=name))\n",
    "    fitted_models[name] = pipe\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "print(\"\\nModel Comparison:\\n\", results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382002c9-96d1-4148-af79-51a5192e63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Hyperparameter Tuning (Random Forest)\n",
    "# =====================================================\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "rf_pipe = models[\"Random Forest\"]\n",
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [150, 200, 300],\n",
    "    \"model__max_depth\": [None, 10, 20, 40],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=8,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=tscv,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best RF Params:\", rf_search.best_params_)\n",
    "rf_best = rf_search.best_estimator_\n",
    "results.append(eval_regression(y_test, rf_best.predict(X_test), \"Random Forest (tuned)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902b4ba-0369-4c38-8d23-dbe546b84bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Save Best Model\n",
    "# =====================================================\n",
    "results_df = pd.DataFrame(results).sort_values(\"RMSE\")\n",
    "best_name = results_df.iloc[0][\"model\"]\n",
    "best_model = rf_best if \"tuned\" in best_name else fitted_models[best_name]\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_path = f\"models/best_model_{best_name.replace(' ', '_')}.joblib\"\n",
    "dump(best_model, model_path)\n",
    "print(f\"\\n✅ Saved best model: {best_name} → {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49c505-2455-4ee7-a9b3-bd76b92d2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Preview Predictions\n",
    "# =====================================================\n",
    "preview = pd.DataFrame({\n",
    "    \"y_true\": y_test.reset_index(drop=True)[:10],\n",
    "    \"y_pred\": pd.Series(best_model.predict(X_test)[:10])\n",
    "})\n",
    "print(\"\\nPrediction Preview:\\n\", preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410eec17-c939-47bf-b84c-82874f103e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b71b1f-1c6f-4ebe-993b-6b47b8496a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b85cf-97e2-417a-b30d-2f9eb56dfc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b626c-e103-4caa-b06d-a7d548154371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904c2c7-5d8b-426c-bacd-62ba96e181d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65383122-f9de-4f63-9437-1f41c876fcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
